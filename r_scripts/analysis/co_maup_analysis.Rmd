---
title: "Environmental Epidemiology and the Modifiable Areal Unit Problem"
author: "Ryan Gan"
date: '2018-03-22'
output:
  html_document:
    df_print: paged
editor_options:
  chunk_output_type: inline
---

# Introduction

Environmental epidemiology rarely has individual-level estimates of exposure for study participants/outcomes observations. Exposure it air pollution is a good example of this short-coming, where collection of individual-level particulate exposure is rare as the time contraints and burden on participants are costly. Furthermore, in order to evaluate the relationship with relatively rare outcomes like hospitalizations or mortality, large cohorts of subjects would need to be followed for an extended period of time. Therefore, it is common to assign exposure to air pollution based on reported place of residence as proxy for invidiual-level exposure. 

In the United States, administrative healthcare claims data can offer sufficient sample sizes in rare events for both time and space. However, detailed location of residence is often not available. Therefore, exposure is often assigned based on a arbitrary spatial unit such as county (used for political reasons) or ZIP code (used for postal delivery). This variation in spatial resolution can result in different results and is known as the modifiable areal unit problem (MAUP). This paper explores the association between air pollution, measured by PM~2.5~, and cardiopulmonary mortality and morbidity and how results may differ based on the unit exposure is assigned.

For this particular set of analyses, I want to estimate the cardiopulmonary morbidity/mortality of PM~2.5~ population-weighted and assigned at the county-level, zipcode-level, PM~2.5~ area-weighted and assigned at the county- and zipcode-level, and finally PM~2.5~ 15 km^2^ grid level. 

I will use Colorado mortality and inpatient hospital discharge data I received from Kirk Bol at CDPHE. I have residential location of county, zipcode, and a 3x3 grid size. This document only focuses on the association of PM~2.5~ assigned at the county-level to comply with the spatial resolution Rish has.

```{r library}
# libraries
library(tidyverse) # data wrangle/plot
library(survival) # conditional logistic models
library(splines) # splines
library(lubridate) # works with dates
library(broom) # tidy model output
library(stringr) # tidy strings
library(sf) # tidy simple features 

# knitr options
knitr::opts_chunk$set(fig.width=8, fig.height=6, quite = T, message = F)
```

## Study Maps

Setting up study map of county and grid.

Creating bbox_clip function to clip different shape objects by latitude and longitude.

```{r bbox_clip_function}
# clip by bbox function ------
bbox_clip <- function(sf, bbox) {
  # find the CRS of the sf object
  crs <- sf::st_crs(sf)$proj4string
  # create matrix
  x <- c(bbox[1], bbox[1], bbox[3], bbox[3], bbox[1])
  y <- c(bbox[2], bbox[4], bbox[4], bbox[2], bbox[2])
  coords <- matrix(cbind(x, y), ncol=2)
  # create polygon and assign same coord crs as sf object
  coords_poly <- sp::Polygon(coords)
  bbox_poly <- sp:: SpatialPolygons(list(sp::Polygons(list(coords_poly),
    ID = "bbox")), proj4string = sp::CRS(crs))
  # convert to sf feature
  bbox_sf <- st_as_sf(bbox_poly)
  # clip sf object
  clipped_sf <- sf[bbox_sf,]
  return(clipped_sf)
}

# clipping bounding box
study_bbox <- st_bbox(c(xmin=-105.3, xmax=-104.5, ymax=41, ymin = 38))
```

Reading in Colorado counties and grid simple features. I'm also going to subset a simple features dataframe to include counties with bigger cities on the Front Range. I'm also going to include Pueblo, which normally is not considered Front Range, but it has some air pollution stations.

```{r sf_objects}
# fips front range
front_range_fips <- paste0("08", c("001", "005", "013", "014", "031", "035", 
                                   "041", "059", "069", "101", "123"))
# read county sf
co_county_sf <- st_read(dsn = "../../data/shapefiles/us_county/") %>% 
  filter(STATEFP == "08") %>% 
  mutate(fips = paste0(STATEFP, COUNTYFP),
         study_county = if_else(fips %in% front_range_fips, 1, 0))
  
# subset county
co_sub_sf <- co_county_sf %>% 
  filter(fips %in% front_range_fips)

# output wgs84 projection
wgs84 <- st_crs(co_county_sf)

# read grid ----
grid_sf <- st_read(dsn = "../../data/shapefiles/co_krig_grid/")
# assign wgs84
st_crs(grid_sf) <- wgs84

# create grids in front range fips; some counties may not be front-range, but
# this is a quick way to do it
front_range_grid <- grid_sf[filter(co_county_sf, fips %in% front_range_fips), ]

# clipping bounding box
study_bbox <- st_bbox(c(xmin=-105.3, xmax=-104.5, ymax=41, ymin = 38))
```

Reading in I-25 and I-70 simple features for reference.

```{r interstate_sf}
# read in colorado roads shapefile
interstate <- st_read(paste0("../../data/shapefiles/tl_2015_08_prisecroads"), 
                      layer = "tl_2015_08_prisecroads") %>% 
  # filter to I25 lines
  filter(RTTYP == "I") %>% 
  st_transform(crs = wgs84)

# interstate clip
i_clip <- bbox_clip(interstate, study_bbox)
```

Reading in city boundary simple features.

```{r city_sf}
# read in city polygons 2010
city <- st_read("../../data/shapefiles/Colorado_City_Point_Locations/", 
                layer = "Colorado_City_Point_Locations") %>% 
  st_transform(crs = wgs84)

# limit cities 
city_points <- city %>% 
  filter(NAME %in% c("FORT COLLINS", "PUEBLO", "GREELEY", "BOULDER", "DENVER",
                     "COLORADO SPRINGS")) %>% 
  mutate(city = stringr::str_to_title(NAME))
```

Reading 2015 population estimate geotiff for Colorado. I made this file for the ALA project from the SEDAC 2015 global estimate.The resolution is on the finer 3x3 grid resolution. I could consider plotting based on the 15x15 km grid.

```{r population_raster}
# read colorado 2015 population raster
co_pop_2015 <- raster::raster("../../data/shapefiles/2015-ColoradoPopDensity.tif")
# extract bbox of clipped county subset
fr_extent <- raster::extent(study_bbox[c(1,3,2,4)])
# raster
fr_pop_2015 <- raster::crop(co_pop_2015, fr_extent)

# i'm going to create a shapefile/simple features; easier to plot
front_range_pop_sf <- st_as_sf(raster::rasterToPolygons(fr_pop_2015)) %>% 
  rename(popden = X2015.ColoradoPopDensity) %>% 
  # filtering to cells > 100 
  filter(popden > 100)

# cut once more to county shapefile so that populations outside the counties are not present
pop_clip <- front_range_pop_sf[co_sub_sf,]
```

Inset map of shaded counties that make up the study area of Front Range counties and basically where most people live in Colorado..

```{r state_map}
# create county inset map
inset_map <- ggplot(co_county_sf) +
  geom_sf(aes(fill = as.factor(study_county)), color = "black", alpha = 0.5, 
          size = 0.5) +
  scale_fill_manual(values = c(NA, "red"), guide = F) +
  #geom_sf(data = grid_sf, fill = NA, color = "red", size = 0.1) +
  ggtitle("Colorado: Study Area Counties") +
  theme(plot.title = element_text(size = 12),
        panel.background = element_blank(),
        panel.grid.major = element_line(colour = 'transparent'),
        panel.grid.minor = element_blank(),
        axis.text = element_blank(),
        axis.ticks = element_blank(),
        axis.title = element_blank(),
        plot.background = element_rect(fill = "transparent", 
                                       color = "transparent"))
inset_map
```

Creating finer detailed study map.

```{r study_map}
# plot map
study_map <-ggplot(pop_clip) +
  # start with plot of simple features of populations
  geom_sf(aes(fill=popden), color = NA) +
  # define aesthetics of poipulation
    scale_fill_gradient(name = expression("Population per km"^2), 
      low = "#26d0ce", high = "#1a2980") +
  # plot lines of counties
  geom_sf(data = co_sub_sf, color = "black", 
          fill = "transparent", size = 0.5) +
  # plot i-25 and i-70
  geom_sf(data = i_clip, aes(color = "Interstate"), show.legend = "line") +
  # plot study grid
  geom_sf(data = front_range_grid, aes(color = "Study Grid"), 
          fill = "transparent", 
          size = 0.1, show.legend = "line") +
  # custom colors for interstate and study grid
  scale_color_manual(values = c("Interstate" = "#0f9b0f", 
                                "Study Grid" = "red"), 
    labels = c("Interstate", "Study Grid"),
    name = "Boundary") + 
  # major city points and names
  geom_point(data = city_points, aes(x = LONG, y = LAT), color = "#3f2b96") +
  geom_text(data = city_points, aes(x = LONG, y = LAT, label = city), 
             color = "#3f2b96", size = 4, hjust = 1, vjust = -0.6) +
  # theme
  theme(panel.background = element_blank(),
        panel.grid.major = element_line(colour = 'transparent'),
        panel.grid.minor = element_blank(),
        axis.text = element_blank(),
        axis.ticks = element_blank(),
        axis.title = element_blank(),
        legend.key = element_rect(fill = NA, colour = NA, size = 0.25))

study_map
```

Final map with inset. Using the grid package. I will add a scale and compass. Open to suggestions on color and what is shown. I had the grid on the inset map but it made it hard to see study counties.I thought of adding ZIP Code, but it might make the map unreadable. I'm also not sure I liked the pieces of the grid over a nice rectangle, but these are the grids that would have any contribution to the counties the are in or touch. Should I exclude Pueblo from analysis since it's not really in Front Range? Ask Kate for her performance statistics.

```{r map_w_inset}
# save map
# tiff(filename = "study_map.tiff", w=850, h)
grid::grid.newpage()
vpmain <- grid::viewport(width = 1, height = 1, x = 0.5, y = 0.5)
vpinset <- grid::viewport(width = 0.25, height = 0.25, x = 0.7, y = 0.85)
print(study_map, vp = vpmain)
print(inset_map, vp = vpinset)
```

## PM~2.5~ Exposure

Setting up funlag function to create lagged datastructures. 

```{r funlag}
# defining a lag function
funlag <- function(var, n=6){
  var <- enquo(var)
  indices <- seq_len(n)
  map( indices, ~quo(lag(!!var, !!.x)) ) %>% 
    set_names(sprintf("%s_lag%d", rlang::quo_text(var), indices))
}
```

### Grid Exposure

Import grid exposure values. I don't think I want to look at smoke values for this particular MAUP analysis as I think it will over-complicate the message. I'm only going to look at lagged PM~2.5~.

The following code reads in the grid-specific PM~2.5~ estimated using ordinary kriging and regrided NARR temperature data.

```{r grid_exp_impor}
# read grid pm
grid_pm <- read_csv("../../data/smoke/1015-grid_pm.csv", 
                    col_types = "cDdddd") %>% 
  mutate(pm_diff_grid = pm25_grid - sbg_pm_grid,
         month = as.factor(lubridate::month(date)), # extract month as factor
         year = as.factor(lubridate::year(date)), # extract year as factor
         season = as.factor(case_when(month %in% c(12, 1, 2) ~ "winter",
                                      month %in% c(3:5) ~ "spring",
                                      month %in% c(6:8) ~ "summer",
                                      month %in% c(9:11)~ "fall")),
         # set krig values lower than 0 to 0
         pm25_grid = if_else(pm25_grid < 0, 0, pm25_grid),
         smk5_g_hms = if_else(pm_diff_grid > 5 & 
                                month %in% c(4:10) & hms_grid == 1, 1, 0),
         # transforming pm kriged estimates to a 10 unit increase in pm
         pm25_g_10u = pm25_grid/10) %>% 
  # sorting by fips and date to estimate lag for each county by date
  arrange(GRID_ID, date) %>% 
  # group by fips 
  group_by(GRID_ID) %>%
  # apply funlag to create lagged estimates for pm2.5 and temperature
  mutate(., !!!funlag(pm25_g_10u,6), !!!funlag(temp_f_grid, 6), 
         !!!funlag(smk5_g_hms)) %>% 
  select(-c(month, year)) %>% 
  ungroup()
```

### Zip Exposure

Spot for zip exposure when Jingyang finishes.

### County Exposure

Import population-weighted county exposures, transform PM~2.5~ estimates to interpret a 10 ug/m^3^ increase in PM~2.5~ and create lagged estimates of PM~2.5~ and temperature. 

```{r import_county_pm}
county_pm <- read_csv(paste0("../../../meta_wildfire/data/smoke/",
  "1015-county_popwt_pm.csv")) %>% 
  # limiting to colorado counties only by reading 1st 2 digs of 5-dig fips code
  filter(str_sub(fips,start=1,end=2) %in% c("08")) %>% 
  rename(pm25_c = pm_krig, sbg_pm_c = bg_pm, pm_diff_c = pm_smk, hms_c = hms,
         temp_f_c = temp_f, aqi_c = aqi, aqi_cat_c = aqi_cat) %>% 
  mutate(pm_diff_c = pm25_c - sbg_pm_c,
         # transforming pm kriged estimates to a 10 unit increase in pm
         pm25_c_10u = pm25_c/10) %>% 
  # sorting by fips and date to estimate lag for each county by date
  arrange(fips, date) %>% 
  # group by fips 
  group_by(fips) %>%
  # apply funlag to create lagged estimates
  mutate(., !!!funlag(pm25_c_10u,6), !!!funlag(temp_f_c, 6)) %>% 
  select(-c(month, year))
```

Subset grid and PM data for small-multiples plotting.

```{r pm_df}
# load grid id key
grid_key <- read_csv("../../data/shapefiles/wrfgrid_key.csv", 
                     col_types = cols(.default = "d", GRID_ID = "c", 
                                      WRFGRID_ID = "c")) %>% 
  select(GRID_ID, WRFGRID_ID)

# find county intersects with grid id
grid_county_key <- st_intersection(co_sub_sf, front_range_grid) %>% 
  select(GRID_ID, fips, NAME) %>% 
  mutate(GRID_ID = as.character(GRID_ID),
         county_name = as.character(NAME)) %>% 
  select(-NAME)
# remove geometry atribute
st_geometry(grid_county_key) <- NULL

# county names
county_names <- grid_county_key %>% 
  group_by(county_name, fips) %>% 
  summarise(grid_n = n())

# subset colorado grid pm to only study counties
fr_grid_pm <- grid_pm %>% 
  filter(GRID_ID %in% front_range_grid$GRID_ID) %>% 
  # join county id 
  left_join(grid_county_key, by = "GRID_ID")

# subset county pm to front range counties
fr_county_pm <- county_pm %>% 
  filter(fips %in% unique(grid_county_key$fips)) %>% 
  left_join(county_names, by = "fips")
```


### Plot of Grid Time Series in Each Study County

County population-weighting PM~2.5~ (red line) tracks well with grid-level estimates (blue).

I could geo_facet this where the small-multiples are arranged spatially to county locations. I think that would be a nice touch.

```{r pm_plot}
pm_plot <- ggplot(data = fr_grid_pm, 
                  aes(x=date, y=pm25_grid, group = county_name)) +
  geom_line(color = "blue") +
  geom_line(data = fr_county_pm, 
            aes(x=date, y = pm25_c, group = county_name), 
            color = "red", alpha = 0.5) +
  facet_wrap(~county_name) +
  xlab("Date") +
  ylab("PM2.5 ug/m^3") +
  theme_minimal()

pm_plot
```

There is probably a better way to present this, but I'm moving on for now.

## Outcomes Data Frames

For inpatient hospitalization, I have data provided by Colorado Hosptial Association and Colorado Department of Public Health and Environment from 2010-01-01 to 2015-09-01 (when claims shifted from ICD9 to ICD10). I am evaluating inpatient hospitalizations admitted through the emergency room to capture acute events and not scheduled events. I am also evaluating only aggregate respiratory and cardiovascular outcomes (not getting in to specific outcomes for these analyses to focus on MAUP). 

For mortality data, I have vital statistics from the Colorado Departmen of Public Health and Environment from 2010-01-01 to 2015-12-01. I am evaluating underlying cause of death using ICD-10 codes. I am only looking at aggregate respiratory and cardiovascular. 

Loading time-stratified case-crossover data frames I saved as list objects. I'm going to limit both the morbidity and mortality dataframes to cardiovscular disease and respiratory outcomes. I have also loaded the ICD-9 codes used to code a primary diagnosis and ICD-10 codes used to code underlying cause of death. Starting by loading mortality data.

```{r cvd_resp_mortality}
# load casecross  mortality list
load("../../data/health/co_mortality_cc_list.RData") 
# load icd10 outcome list
load("../../data/health/icd10_outcome.RData")

# co cvd and resp mortaility
co_death_list <- casecross_list[c(1,4)]

# removing casecross_list to save memeory
rm(casecross_list)
```

Loading morbidity data.

```{r resp_cvd_morbidity}
# load casecross list
load("../../data/health/1015-co_morbidity_casecross_list.RData")
# load icd9
load("../..//data/health/icd9_outcome_vectors.RData")

# co hosp list
co_hosp_list <- co_morbidity_cc_list[c(1,6)]

# removing 
rm(co_morbidity_cc_list)
```

### Descriptives

I think a small-multiples time-series plot of CVD hospitalizations and mortality and respiratory hospitalizations and mortality would be nice here for the counties of interest. I would also add the total n for each time-series in the facet header to provide counts of observed outcomes.

I think I'm going to calculate a weekly rate for the entire counties and only cardiovascular and respiratory for a couple reasons, but mainly to avoid any potential rare events that may let somesome be identified on a particular date. I'm really after major trends that may bias results. 

This would be county-specific mortality rates for the Front Range.
```{r mortality_rate}
# read in county population denominators for colorado
county_pop <- read_csv("../../data/health/2016-colorado_population.csv") %>% 
  rename(fips = GEO.id2) %>% 
  select(fips, respop72010:respop72015) %>% 
  filter(fips %in% front_range_fips) %>% 
  gather(year, population, -fips) %>% 
  mutate(year = as.numeric(str_sub(year, start = 8)))

# assign death outcome
death_outcome <- names(co_death_list)

# time series of weekly death and rate for cardiovascular and respiratory
death_ts <- map2(.x = co_death_list,  .y = death_outcome, 
                 ~ filter(.x, outcome == 1 & fips %in% front_range_fips) %>% 
                   mutate(date = as.Date(as.character(date_of_death)),
                          week = floor_date(date, unit = "week")) %>% 
                   group_by(week, fips) %>% 
                   summarise(n = n()) %>% 
                   left_join(county_names, by = "fips") %>% 
                   mutate(year = year(week),
                          outcome = .y) %>% 
                   left_join(county_pop, by = c("fips", "year")) %>% 
                   mutate(rate_per_100k = (n/population)*100000) %>% 
                   filter(week >= "2010-01-01" & week <= "2015-12-31")) %>% 
  map_dfr(., rbind)
```

Morbidity weekly count time series.

```{r hosp_rate}
# hosp_names
hosp_outcome <- names(co_hosp_list)
# time series of weekly death and rate for cardiovascular and respiratory
hosp_ts <- map2(.x = co_hosp_list,  .y = hosp_outcome, 
                 ~ filter(.x, outcome == 1 & fips %in% front_range_fips) %>% 
                   mutate(date = as.Date(as.character(date)),
                          week = floor_date(date, unit = "week")) %>% 
                   group_by(week, fips) %>% 
                   summarise(n = n()) %>% 
                   left_join(county_names, by = "fips") %>% 
                   mutate(year = year(week),
                          outcome = .y) %>% 
                   left_join(county_pop, by = c("fips", "year")) %>% 
                   mutate(rate_per_100k = (n/population)*100000) %>% 
                   filter(week >= "2010-01-01" & week <= "2015-12-31")) %>% 
  map_dfr(., rbind)
```

Bind time series together.

```{r outcomes_ts}
fr_death_ts <- death_ts %>% 
  group_by(week, outcome) %>% 
  summarise(n = sum(n), pop = sum(population)) %>% 
  mutate(rate_per_100k = (n/pop)*100000,
         strata = paste0("Mortality: ", outcome)) %>% 
  filter(outcome %in% c("cvd", "resp"))

fr_hosp_ts <- hosp_ts %>% 
  group_by(week, outcome) %>% 
  summarise(n = sum(n), pop = sum(population)) %>% 
  mutate(rate_per_100k = (n/pop)*100000,
         strata = paste0("Morbidity: ", outcome)) %>% 
  filter(outcome %in% c("cvd", "resp"))

# bind together
fr_ts <- bind_rows(fr_death_ts, fr_hosp_ts)

ggplot(fr_ts, aes(x = week, y = rate_per_100k)) +
  geom_point() +
  facet_wrap(~strata, scales = "free_y") +
  ylab("Rate per 100,000 persons") +
  xlab("Date") +
  theme_minimal()
```

There is a peak in mortality and morbidity for respiratory at the end of 2014 start of 2015. I believe this is likely associated with the influenza season that was bad that year. Seasonal analysis may be interesting rather than just warm months.

This plot needs work too. I also want to add a outcome numbers for the months included in the analyses tables.

### Joining PM~2.5~ Estimates

Joining with PM~2.5~ data and also limiting to front range counties. I'm also limiting to summer (June through August).

```{r death_pm_join}
# assign outcome names to each dataframe in list
co_death_list_pm <- co_death_list %>% 
  # for some variables in the casecross dfs, I need to convert to character, then
  # desired format to make sure it's right
  map(~ mutate(., outcome = as.numeric(as.character(outcome)),
               date = as.Date(as.character(date_of_death)),
               month = as.factor(lubridate::month(date)),
               WRFGRID_ID = as.character(wrfgrid_id)) %>%
      # filter out 2016; I don't have pm data yet
      filter(date <= "2015-12-30") %>% 
      # filter to front range
      filter(fips %in% front_range_fips) %>% 
      # remove vars to prevent duplicates
      select(-wrfgrid_id) %>% 
      left_join(grid_key, by = "WRFGRID_ID") %>% 
      left_join(grid_pm, by = c("GRID_ID", "date")) %>% 
      left_join(county_pm, by = c("fips", "date"))) %>% 
  # add outcome name to each dataframe
  map2(.x = ., .y = death_outcome, ~mutate(.x, out_name = .y)) 
```

## Distributed Lag

Set up distributed lag function.

```{r distributed_lag_fun}
distribute_that_lag <- function(lag_mod, strata, exposure_basis) {
  # output pm basis estimates
  parms <- broom::tidy(lag_mod) %>% 
    filter(stringr::str_detect(term, strata)) %>% 
    select(estimate) %>% 
    as_vector()
  # output estimate names for cov matrix
  names <- stringr::str_subset(names(lag_mod$coefficients), strata)
  # estimate associations
  est <- exposure_basis %*% parms
  # estimate standard error for each interval
  # time variable
  time <- ((rep(1:length(est))-1))
  # covariance matrix for knots 
  cov_mat <- as.matrix(vcov(lag_mod))[names, names]
  # estimate variance of spline
  var <- exposure_basis %*% cov_mat %*% t(exposure_basis)
  # estimate lag ----
  # estimate standard error for each lag day for smoke
  l_se <- sqrt(diag(var))
  # calculate lower and upper bound for smoke
  l_est_l95 <- est + (l_se*qnorm(1-0.975))
  l_est_u95 <- est + (l_se*qnorm(0.975))
  l_type <- "lag"
  # lag dataframe
  l_df <- data.frame(strata, l_type, time, 
                     exp(est), exp(l_est_l95), exp(l_est_u95), 
                     row.names = NULL) 
  # assign column names
  colnames(l_df) <- c("strata", "type", "time", 
                      "odds_ratio", "lower_95", "upper_95")
  # cumulative estimates
  c_est <- sapply(seq_along(est), function(x){
    sum(est[1:x])
  })
  # stderr cumulative effect smk
  c_se <- sapply(seq_along(c_est), function(y){
    sqrt(sum(var[1:y,1:y]))
  })
  # estimate 95% CI
  c_l95 <- c_est+(c_se*qnorm(1-0.975))
  c_u95 <- c_est+(c_se*qnorm(0.975))
  # type
  c_type <- "cumulative"
  # return dataframe
  c_df <- data.frame(strata, c_type, time, exp(c_est), 
                     exp(c_l95), exp(c_u95), row.names = NULL) 
  # assign column names
  colnames(c_df) <- c("strata", "type", "time", 
                      "odds_ratio", "lower_95", "upper_95")
  # bind lagged and cumulative 
  lag_est <- rbind(l_df, c_df) %>% 
    mutate(strata = as.character(strata),
           type = as.character(type))
  # return lagged estimate
   return(lag_est)
 } # end lag estimate function
```

## Mortality and PM~2.5~ Association

Model fit of distributed lag spline of PM~2.5~ and temperature.

```{r death_dl_fit}
# distributed lag function
death_dl_fit <- map(co_death_list_pm, function(x){
  # output dataframe from list
  data <- x %>% 
    mutate(date = as.Date(date),
           outcome = as.numeric(as.character(outcome))) %>%
    #filter(month %in% 5:9) %>% 
    filter(season == "summer") %>% 
    # remove missing lagged data
    filter(!is.na(pm25_g_10u_lag6))
  # output outcome name
  out_name <- as.character(unique(data$out_name))
  # create lagged matrix
  pm_mat <- as.matrix(select(data, contains("pm25_g_10u")))
  temp_mat <- as.matrix(select(data, contains("temp_f_grid")))
  # set up df_pm and df_temp
  df_pm <- 2:4
  df_temp <- 2:4
  # set up combinations of df_pm and df_temp
  df_combo <- expand.grid(df_pm, df_temp)
  colnames(df_combo) <- c("df_pm", "df_temp")
  # bind in outcome name
  df_combo$outcome <- out_name
  
  outcome_fit <- apply(df_combo, 1, function(fit){
    # define lagged basis spline for pm
    p_exp_b <- ns(0:(ncol(pm_mat)-1), df = as.numeric(fit[[1]]), intercept = T)
    # pm basis
    pm_basis <- pm_mat %*% p_exp_b
    
    # temp basis
    t_exp_b <- ns(0:(ncol(temp_mat)-1), df = as.numeric(fit[[2]]), intercept = T)
    temp_basis <- temp_mat %*% t_exp_b
    # run lagged model
    lag_mod <- clogit(outcome ~ pm_basis + temp_basis + 
                      strata(id), data = data)
    # find aic and join to df_combo
    aic <- AIC(lag_mod)
    return(aic)
    }) # end fit function
  # bind outcome fit to df_combo list
  df_combo$aic <- outcome_fit
  return(df_combo)
  }) %>% 
  # bind cvd and resp together
  map_dfr(.,rbind)

# best fit by lowest aic
death_min_aic <- death_dl_fit %>% 
  group_by(outcome) %>%
  slice(which.min(aic)) %>% 
  arrange(desc(outcome))
# print best fit by aic
print(death_min_aic)
```

Model distributed lag results based on best fit by AIC. 

```{r death_dl_grid}
# create fit list to use with purrr:map2
fit_list <- split(death_min_aic, seq(nrow(death_min_aic)))
# distributed lag function
dl_death_results  <- map2(co_death_list_pm, fit_list, function(df, fit){
  # output dataframe from list
  data <- df %>% 
    mutate(date = as.Date(date),
           outcome = as.numeric(as.character(outcome))) %>%
    #filter(month %in% c(5:9)) %>% 
    filter(season == "summer") %>% 
    # remove missing lagged data
    filter(!is.na(pm25_g_10u_lag6)) 
  
  # output outcome name
  out_name <- as.character(unique(data$out_name))
  # output matrices
  pm_mat <- as.matrix(select(data, contains("pm25_g_10u")))
  temp_mat <- as.matrix(select(data, contains("temp_f_grid")))
  
  # define lagged basis spline for pm
  p_exp_b <- ns(0:(ncol(pm_mat)-1), df = fit$df_pm, intercept = T)
  # pm basis
  pm_basis <- pm_mat %*% p_exp_b
  
  # temp basis
  t_exp_b <- ns(0:(ncol(temp_mat)-1), df = fit$df_temp, intercept = T)
    temp_basis <- temp_mat %*% t_exp_b
    
  # run lagged model
  lag_mod <- clogit(outcome ~ pm_basis + temp_basis + 
                      strata(id), data = data)
  
  # estimate lag estimate
  lag_est <- distribute_that_lag(lag_mod, strata = "pm", 
                                 exposure_basis = p_exp_b) %>% 
    mutate(outcome = out_name) %>% select(outcome, strata:upper_95)
  return(lag_est)
  }) %>%  #end lappply
  # bind rows
  map_dfr(.,rbind) %>% 
  filter(type == "cumulative") %>% 
  mutate(exp_area = "grid")
```

Estimation of population-weighted county PM~2.5~ and mortality.

```{r dl_county_results}
# distributed lag function
death_dl_c_results  <- map2(co_death_list_pm, fit_list, function(df, fit){
  # output dataframe from list
  data <- df %>% 
    mutate(date = as.Date(date),
           outcome = as.numeric(as.character(outcome))) %>%
    #filter(month %in% 5:9) %>% 
    filter(season == "summer") %>% 
    # remove missing lagged data
    filter(!is.na(pm25_g_10u_lag6)) 
  
  # output outcome name
  out_name <- as.character(unique(data$out_name))
  # output matrices
  pm_mat <- as.matrix(select(data, contains("pm25_c_10u")))
  temp_mat <- as.matrix(select(data, contains("temp_f_c")))
  
  # define lagged basis spline for pm
  p_exp_b <- ns(0:(ncol(pm_mat)-1), df = fit$df_pm, intercept = T)
  # pm basis
  pm_basis <- pm_mat %*% p_exp_b
  
  # temp basis
  t_exp_b <- ns(0:(ncol(temp_mat)-1), df = fit$df_temp, intercept = T)
    temp_basis <- temp_mat %*% t_exp_b
    
  # run lagged model
  lag_mod <- clogit(outcome ~ pm_basis + temp_basis + 
                      strata(id), data = data)
  
  # estimate lag estimate
  lag_est <- distribute_that_lag(lag_mod, strata = "pm", 
                                 exposure_basis = p_exp_b) %>% 
    mutate(outcome = out_name) %>% select(outcome, strata:upper_95)
  return(lag_est)
  }) %>%  #end lappply
  # bind rows
  map_dfr(.,rbind) %>% 
  filter(type == "cumulative") %>% 
  mutate(exp_area = "county")
```

Plot showing the cumulative effect of up to a week of a 10 ug/m^3^ increase in PM~2.5~ on risk of mortality with an underlying cause of death for cardiovascular and respiratory. Right now I'm showing PM~2.5~ assigned using the grid IDs, and county-level population weighting. Good news is that population-weighting seems to produce similar results. 

```{r death_result_plot}
plot_df <- bind_rows(dl_death_results, death_dl_c_results) %>% 
  mutate(group = paste0(outcome, ": ", exp_area))

# plot results
plot <- ggplot(plot_df, aes(x=time, y=odds_ratio)) +
  geom_line(colour = "black", size = 1) +
  geom_ribbon(aes(ymin = lower_95, ymax = upper_95), 
              fill = "grey", alpha = 0.5) + 
  scale_x_continuous(breaks = c(seq(0,7, by=1))) +
  geom_hline(yintercept = 1, linetype = 2, colour = "black") +
  # adding facet wrap to estimate for each outcome
  facet_wrap(~ group, scales = "free_y") +
  ylab(expression("Odds Ratio: 10 ug/m^3 increase PM2.5")) +
  xlab("Lagged Days") +
  ggtitle("Risk of Mortality for a 10 ug/m") +
  theme(panel.grid.major.x = element_blank(),
        panel.grid.major.y = element_line(linetype = "dotted"),
        panel.grid.minor = element_blank()) +
  theme_minimal()
# plot cumulative effect
print(plot)
```

Risk for mortality with cardiovascular as the underlying cause of death is increased by roughtly 10% after 3 to 4 days of elevated exposure to PM~2.5~. The 95% CI indicates this value over the time period could be as low as a 1% increase in risk, but could be as high as a 19% increase in risk.

Risk for mortality with respiratory as the underlying cause of death is increased by roungly 9% a day or so of a 10 ug/m^3^ increase in PM~2.5~ with the risk increasing to as high as 12% following two days of increased PM~2.5~ exposure. The 95% CI indicates that the value could be as low as essentially no increase (0%) in risk, and as high as 10% to 20% increase in risk from days 0 to 2.

Note: It would probably be a good idea to see if degrees of freedom fit would be the same for each.

Itterating through list of case-crossover dataframes and running distributed lag models based on best degree of freedom fit for each temperature and pm spline.

Seasonal analysis not included because it needs work.

```{r seasonal_fit_death, eval=F, include=F}
# distributed lag function
death_season_fit <- map(co_death_list_pm, function(x){
  # seasonal vector
  season_vec <- c("spring", "summer", "fall", "winter")

  # seasonal results
  seasonal_fit <- map(season_vec, function(s){  
  # output dataframe from list
  data <- x %>% 
    filter(season == s) %>% 
    mutate(date = as.Date(date),
           outcome = as.numeric(as.character(outcome))) %>%
    # remove missing lagged data
    filter(!is.na(pm25_g_10u_lag6))

  # output outcome name
  out_name <- as.character(unique(data$out_name))
  # create lagged matrix
  pm_mat <- as.matrix(select(data, contains("pm25_g_10u")))
  temp_mat <- as.matrix(select(data, contains("temp_f_grid")))
  # set up df_pm and df_temp
  df_pm <- 2:4
  df_temp <- 2:4
  # set up combinations of df_pm and df_temp
  df_combo <- expand.grid(df_pm, df_temp)
  colnames(df_combo) <- c("df_pm", "df_temp")
  # bind in outcome name
  df_combo$outcome <- out_name
  # df season
  df_combo$season <- s
  
  outcome_fit <- apply(df_combo, 1, function(fit){
    # define lagged basis spline for pm
    p_exp_b <- ns(0:(ncol(pm_mat)-1), df = as.numeric(fit[[1]]), intercept = T)
    # pm basis
    pm_basis <- pm_mat %*% p_exp_b
    
    # temp basis
    t_exp_b <- ns(0:(ncol(temp_mat)-1), df = as.numeric(fit[[2]]), intercept = T)
    temp_basis <- temp_mat %*% t_exp_b
    # run lagged model
    lag_mod <- clogit(outcome ~ pm_basis + temp_basis + 
                      strata(id), data = data)
    # find aic and join to df_combo
    aic <- AIC(lag_mod)
    return(aic)
    }) # end fit function
  # bind outcome fit to df_combo list
  df_combo$aic <- outcome_fit
  return(df_combo)
  }) %>% 
  map_dfr(., rbind)
  }) %>% 
  # bind cvd and resp together
  map_dfr(.,rbind)

# best fit by lowest aic
death_season_min_aic <- death_season_fit %>% 
  group_by(outcome, season) %>%
  slice(which.min(aic)) %>% 
  arrange(desc(outcome))
# print best fit by aic
print(death_season_min_aic)
```

## Morbidity and PM~2.5~ Association

Joining PM~2.5~ estimates to hosptializations list. I will limit analyses to summer in this model step,.

```{r hosp_pm}
# create list
co_hosp_list_pm <-  co_hosp_list %>% 
  # desired format to make sure it's right
  map(~ select(., id:state) %>% 
        mutate(outcome = as.numeric(as.character(outcome)),
               date = as.Date(as.character(date)),
               month = as.factor(lubridate::month(date)),
               WRFGRID_ID = as.character(WRFGRID_ID)) %>%
      left_join(grid_key, by = "WRFGRID_ID") %>%
      filter(GRID_ID %in% front_range_grid$GRID_ID) %>% 
      left_join(grid_pm, by = c("GRID_ID", "date")) %>% 
      left_join(county_pm, by = c("fips", "date"))) %>% 
      # filter to front range, this will get only colorado
  # add outcome name to each dataframe
  map2(.x = ., .y = hosp_outcome, ~mutate(.x, out_name = .y)) 
```

Finding best-fit dl splines for PM~2.5~ assigned at grid-level based on lowest AIC.

```{r hosp_dl_fit}
# distributed lag function
hosp_dl_fit <- map(co_hosp_list_pm, function(x){
  # output dataframe from list
  data <- x %>% 
    mutate(date = as.Date(date),
           outcome = as.numeric(as.character(outcome)),
           year = year(date)) %>%
    filter(season == "summer") %>% 
    # remove missing lagged data
    filter(!is.na(pm25_g_10u_lag6))
  # output outcome name
  out_name <- as.character(unique(data$out_name))
  # create lagged matrix
  pm_mat <- as.matrix(select(data, contains("pm25_g_10u")))
  temp_mat <- as.matrix(select(data, contains("temp_f_grid")))
  # set up df_pm and df_temp
  df_pm <- 2:4
  df_temp <- 2:4
  # set up combinations of df_pm and df_temp
  df_combo <- expand.grid(df_pm, df_temp)
  colnames(df_combo) <- c("df_pm", "df_temp")
  # bind in outcome name
  df_combo$outcome <- out_name
  
  outcome_fit <- apply(df_combo, 1, function(fit){
    # define lagged basis spline for pm
    p_exp_b <- ns(0:(ncol(pm_mat)-1), df = as.numeric(fit[[1]]), intercept = T)
    # pm basis
    pm_basis <- pm_mat %*% p_exp_b
    
    # temp basis
    t_exp_b <- ns(0:(ncol(temp_mat)-1), df = as.numeric(fit[[2]]), intercept = T)
    temp_basis <- temp_mat %*% t_exp_b
    # run lagged model
    lag_mod <- clogit(outcome ~ pm_basis + temp_basis + 
                      strata(id), data = data)
    # find aic and join to df_combo
    aic <- AIC(lag_mod)
    return(aic)
    }) # end fit function
  # bind outcome fit to df_combo list
  df_combo$aic <- outcome_fit
  return(df_combo)
  }) %>% 
  # bind cvd and resp together
  map_dfr(.,rbind)

# best fit by lowest aic
hosp_min_aic <- hosp_dl_fit %>% 
  group_by(outcome) %>%
  slice(which.min(aic)) %>% 
  arrange(desc(outcome))
# print best fit by aic
print(hosp_min_aic)
```

Estimating effect of grid-level PM~2.5~ on cardioresp hospitalizations in warm months. 

```{r hosp_dl_grid}
# create fit list to use with purrr:map2
hosp_fit_list <- split(hosp_min_aic, seq(nrow(hosp_min_aic)))
# distributed lag function
hosp_dl_pm_results  <- map2(co_hosp_list_pm, hosp_fit_list, function(df, fit){
  # output dataframe from list
  data <- df %>% 
    mutate(date = as.Date(date),
           outcome = as.numeric(as.character(outcome)), 
           year = year(date)) %>%
    filter(season == "summer") %>% 
    # remove missing lagged data
    filter(!is.na(pm25_g_10u_lag6)) 
  
  # output outcome name
  out_name <- as.character(unique(data$out_name))
  # output matrices
  pm_mat <- as.matrix(select(data, contains("pm25_g_10u")))
  temp_mat <- as.matrix(select(data, contains("temp_f_grid")))
  
  # define lagged basis spline for pm
  p_exp_b <- ns(0:(ncol(pm_mat)-1), df = fit$df_pm, intercept = T)
  # pm basis
  pm_basis <- pm_mat %*% p_exp_b
  
  # temp basis
  t_exp_b <- ns(0:(ncol(temp_mat)-1), df = fit$df_temp, intercept = T)
    temp_basis <- temp_mat %*% t_exp_b
    
  # run lagged model
  lag_mod <- clogit(outcome ~ pm_basis + temp_basis + 
                      strata(id), data = data)
  
  # estimate lag estimate
  lag_est <- distribute_that_lag(lag_mod, strata = "pm", 
                                 exposure_basis = p_exp_b) %>% 
    mutate(outcome = out_name) %>% select(outcome, strata:upper_95)
  return(lag_est)
  }) %>%  #end lappply
  # bind rows
  map_dfr(.,rbind) %>% 
  filter(type == "cumulative") %>% 
  mutate(exp_area = "grid")
```

Estimating county-level PM~2.5~ effect on hospitalizations.

```{r dl_hosp_county_results}
# distributed lag function
hosp_dl_c_results  <- map2(co_hosp_list_pm, hosp_fit_list, function(df, fit){
  # output dataframe from list
  data <- df %>% 
    mutate(date = as.Date(date),
           outcome = as.numeric(as.character(outcome)),
           year = year(date)) %>%
    filter(season == "summer") %>% 
    # remove missing lagged data
    filter(!is.na(pm25_c_10u_lag6)) 
  
  # output outcome name
  out_name <- as.character(unique(data$out_name))
  # output matrices
  pm_mat <- as.matrix(select(data, contains("pm25_c_10u")))
  temp_mat <- as.matrix(select(data, contains("temp_f_c")))
  
  # define lagged basis spline for pm
  p_exp_b <- ns(0:(ncol(pm_mat)-1), df = fit$df_pm, intercept = T)
  # pm basis
  pm_basis <- pm_mat %*% p_exp_b
  
  # temp basis
  t_exp_b <- ns(0:(ncol(temp_mat)-1), df = fit$df_temp, intercept = T)
    temp_basis <- temp_mat %*% t_exp_b
    
  # run lagged model
  lag_mod <- clogit(outcome ~ pm_basis + temp_basis + 
                      strata(id), data = data)
  
  # estimate lag estimate
  lag_est <- distribute_that_lag(lag_mod, strata = "pm", 
                                 exposure_basis = p_exp_b) %>% 
    mutate(outcome = out_name) %>% select(outcome, strata:upper_95)
  return(lag_est)
  }) %>%  #end lappply
  # bind rows
  map_dfr(.,rbind) %>% 
  filter(type == "cumulative") %>% 
  mutate(exp_area = "county")
```

Plotting county and grid results for hospitalizations.

```{r hosp_result_plot}
hosp_plot_df <- bind_rows(hosp_dl_pm_results, hosp_dl_c_results) %>% 
  mutate(group = paste0(outcome, ": ", exp_area))

# plot results
hosp_plot <- ggplot(hosp_plot_df, aes(x=time, y=odds_ratio)) +
  geom_line(colour = "black", size = 1) +
  geom_ribbon(aes(ymin = lower_95, ymax = upper_95), 
              fill = "grey", alpha = 0.5) + 
  scale_x_continuous(breaks = c(seq(0,7, by=1))) +
  geom_hline(yintercept = 1, linetype = 2, colour = "black") +
  # adding facet wrap to estimate for each outcome
  facet_wrap(~ group, scales = "free_y") +
  ylab(expression("Odds Ratio: 10 ug/m^3 increase PM2.5")) +
  xlab("Lagged Days") +
  ggtitle("Risk of Hospitalization for a 10 ug/m") +
  theme(panel.grid.major.x = element_blank(),
        panel.grid.major.y = element_line(linetype = "dotted"),
        panel.grid.minor = element_blank()) +
  theme_minimal()
# plot cumulative effect
print(hosp_plot)
```

That 2014 peak of influenza seems to mess with the association with hospitalizations. If I include 2010-2013 summers, the results I get are different.

Consider only presenting mortality results for this paper.


# Thoughts that need to be flushed out

- It looks like populaton-weighting is a good way to minimize some of the bias of MAUP? Or at least provides similar results. I think results for area-weighting will be important here.

- While it may be hard to accurately capture variability in PM~2.5~ exposure on a given day across different spatial units, if you assume within a given spatial unit, we've been able to capture daily variation resonably well, using distributed lag models may help overcome some of these limitations.

- If I'm limiting to aggregated outcomes like all respiratory, or cvd, perhaps it makes sense to limit exposure periods to periods and areas known to be impacted by smoke. Much like our 2012 Washington and 2013 Oregon analysis, and like Colleen Reid's California wildfire paper. 

# Future Steps

- Interaction analysis to evaluate smoke.
