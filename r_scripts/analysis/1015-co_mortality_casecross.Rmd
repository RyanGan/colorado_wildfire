---
title: "Example of Distributed Lag Interaction Model"
author: "Ryan Gan"
date: '2018-03-22'
output:
  html_document:
    df_print: paged
editor_options:
  chunk_output_type: inline
---

# Introduction

In this document, I will show how I estimate the risk for cardiopulmonary mortality from a distributed lag of a continous estimate of PM~2.5~ with an interaction term of a binary classifier of smoke variable. I will use Colorado mortality data I received from Kirk Bol at CDPHE. I have residential location of county, zipcode, and a 3x3 grid size. This document only focuses on the association of PM~2.5~ assigned at the county-level to comply with the spatial resolution Rish has.

I like to set the figure output options of the markdown document to be 8 inches wide and 6 inches tall.

```{r md_setup, include=F}
# knitr options
knitr::opts_chunk$set(fig.width=8, fig.height=6, quite = T, message = F)
```

R libraries used for these analyses. Tidyverse package is a general data wrangling package and contains the ggplot2 package that will be used for creating plots. Survival package contains the clogit function for performing conditional logistic regression. Splines package creates the distributed lag splines. Lubridate works with dates. I also use the broom package, which can take model estimates and output them as a tidy dataframe. Also use the stringr package for working with character strings.

```{r library}
library(tidyverse) # data wrangle/plot
library(survival) # conditional logistic models
library(splines) # splines
library(lubridate) # works with dates
library(broom)
library(stringr)
library(dlnm)
```

## PM~2.5~ Data

Importing county-level population-weighted PM~2.5~ estimates for Western US states. The time frame of estimates are from 2010 to 2015. Kate has estimated from 2016 on I think as well, although my morbidity and mortality data. I won't create descriptive statistics or plots for these data as I did it elsewhere.

Before I import PM~2.5~ data, I'm going to create a lag function called "lagfun" that will estimate lagged estimates. This function requires the Tidyverse pacakge to be loaded.

```{r funlag}
# defining a lag function
funlag <- function(var, n=6){
  var <- enquo(var)
  indices <- seq_len(n)
  map( indices, ~quo(lag(!!var, !!.x)) ) %>% 
    set_names(sprintf("%s_lag%d", rlang::quo_text(var), indices))
}
```

Setting up front-range counties only due to model performance being best where most people live.

```{r fr_fips}
fr_fips <- c("08001", "08005", "08013", "08014", "08031", "08035", "08041",
             "08059", "08069", "08123")
```


Importing county-level PM~2.5~ from csv file. I'm limiting to Colorado, creating binary smoke classifiers, and then creating lagged functions. These data are located in the meta_wildfire repo. Defining the relative path from my current working directory to those data.
```{r pm_import, message=FALSE, warning=FALSE}
# read pm
pm <- read_csv(paste0("../../../meta_wildfire/data/smoke/",
  "1015-county_popwt_pm.csv")) %>% 
  # limiting to colorado counties only by reading 1st 2 digs of 5-dig fips code
  filter(str_sub(fips,start=1,end=2) %in% c("08")) %>% 
  # renaming variable pm_smk to pm_diff; more accurate description of var
  rename(pm_diff = pm_smk) %>% 
  # us
  mutate(day = as.factor(weekdays(date)), # create day of week based on var
         weekend = ifelse(day %in% c("Saturday", "Sunday"), 1, 0),
         month = as.factor(lubridate::month(date)), # extract month as factor
         year = as.factor(lubridate::year(date)), # extract year as factor
         season = as.factor(case_when(month %in% c(12, 1, 2) ~ "winter",
                                      month %in% c(3:5) ~ "spring",
                                      month %in% c(6:8) ~ "summer",
                                      month %in% c(9:11)~ "fall")),
         # creating binary smoke to require 50% of county with smoke overhead
         # and difference between estimate and seasonal background to be >0
         # and to be within the month of April to Octoboer
         smoke0_hms = ifelse(pm_diff > 0 & month %in% c(4:10) & hms > 0.5, 1, 0),
         smoke5_hms = ifelse(pm_diff > 5 & month %in% c(4:10) & hms > 0.1, 1, 0),
         smoke10_hms = ifelse(pm_diff > 10 & month %in% c(4:10) & hms > 0.1, 1, 0),
         smoke15_hms = ifelse(pm_diff > 15 & month %in% c(4:10) & hms > 0.1, 1, 0),
         # transforming pm kriged estimates to a 10 unit increase in pm
         pm = pm_krig/10) %>% 
  # sorting by fips and date to estimate lag for each county by date
  arrange(fips, date) %>% 
  # group by fips 
  group_by(fips) %>%
  # apply funlag to create lagged estimates
  mutate(., !!!funlag(pm,3), !!!funlag(smoke0_hms,3), !!!funlag(smoke5_hms,3),
         !!!funlag(smoke10_hms,3), !!!funlag(smoke15_hms,3), 
         !!!funlag(temp_f, 3)) %>% 
  select(-state, -month) # removing state and month to bind with casecross
```

### Structure of PM~2.5~ Data

Showing first 5 rows of PM~2.5~ dataframe. In addition to PM~2.5~, I have county AQI data for most counties for most days.

```{r head_pm}
head(pm)
```

## Mortality

Loading in a list object that contains time-stratified case-crossover dataframes of where underlying cause of death was defined as cardiopulmonary. I have created referent periods within the same month of death, which I think is appropriate. I don't think we want to expand it beyond this range, especially for older deceased people. Also loading in the ICD10 outcomes I used to define underlying cause of death.

```{r mortality_load}
# load casecrossover list -----
load("../../data/health/co_mortality_cc_list.RData")
# load mortality outcome list
load("../../data/health/icd10_outcome.RData")
```

### Structure of Mortality Data

I can't/won't show what these data look like in this document due to protected health information and HIPAA concerns. Instead, I'll create a made up example of a person (female, age 50) who died on 2010-12-16 from an underlying respiratory condition (ICD10 == Jxxxx), indicated by outcome == 1 and lived in Denver County. I'll create refernt dates on the same day of other weeks in the month, indicated by outcome == 0. I have the FIPS of Denver and dates to join exposure values to. 

```{r case_cross_structure_example}
id <- "123abc"
sex <- "F"
age <- 50
date <- as.Date(c("2010-12-02", "2010-12-09", "2010-12-16", 
                  "2010-12-23", "2010-12-30"))
outcome <- c(0,0,1,0,0)
ucod <- "JXX" # underlying cause of death something repiratory indicated by J
fips <- "08031" # Denver county
# print example casecross dataframe
print(data.frame(id, date, outcome, ucod, sex, age, fips))
```

I need to manipulate the case-crossover dataframes in the list a bit. I like to assign a outcome name in the dataframe, and I'm going to attempt to control for seasonal confounding by restricting my analyses to the wildfire season, defined as April to October. I am also going to join with PM~2.5~ data by fips and date. I use the purrr map functions that are part of the tidyverse package to itterate over the lists.

```{r cc_list_wrangle}
# extract a vector of outcome names from the icd10 outcomes list 
outcomes <- names(icd10_outcomes)

# reduce case-crossover list to only summer months and join pm
co_cc_list <- casecross_list %>% 
  # for some variables in the casecross dfs, I need to convert to character, then
  # desired format to make sure it's right
  map(~ mutate(., outcome = as.numeric(as.character(outcome)),
               date = as.Date(as.character(date_of_death)),
               month = as.factor(lubridate::month(date))) %>% 
      # filter out 2016; I don't have pm data yet
      filter(date <= "2015-12-30") %>% 
      filter(month %in% 6:8) %>% 
      filter(fips %in% fr_fips) %>% 
      left_join(pm, by = c("fips", "date"))) %>% 
  # add outcome name to each dataframe
  map2(.x = ., .y = outcomes, ~mutate(.x, out_name = .y))
```

## Mortality Counts by Outcome

Counting up number of deaths from 2010 to 2015 that occured in April - October for cardiopulmonary outcomes. We can modify this code to include different age or sex strata. 

I have general categories of underlying cause of death for respiratory, and then asthma and chronic obstructive pulmonary diease. Note, the sample size of asthma is super small and likely not worth analyzing in the state. For the cardiovascular outcomes, I have subclassifications of heart failure, cardiac arrest, ischemic heart disease, myocardial infarction, and cerebrovascular.

There is also a weird thing with Colorado where county coroners are elected and don't need to have any medical training... This usually isn't a big deal in larger counties like Denver, where even the elected officials will usually contract out the autopsy to physicians, but in some smaller or rural counties, the underlying cause of death could be inaccurate. I'm not sure it's still a big issue, but something to consider.

```{r death_counts}
# estimate deaths 
death_counts <- co_cc_list %>% 
  map_dfr(. , function(df){
    counts <- df %>% 
      filter(outcome == 1) %>% 
      group_by(out_name) %>% 
      summarise(n = n())
    })
# print death counts
death_counts
```

## Same-Day Associations 

Evaluating a 10 ug/m^3^ increase in county-level population-weighted PM~2.5~ and risk for mortality for certain cardiopulmonary underlying causes of deaths. Again, I use a variant of purrr map function, map_dfr to take each dataframe in the list, and run a conditional logistic regression between the outcome of interest and PM~2.5~, adusting for temperature. I output the odds ratio and 95% confidence intervals as a dataframe. You could also use R's apply type functions as well, which I'll do if I want to run multiple models in parallel to save time.

```{r same_day_pm}
# same-day association with pm and mortality during wildfire season
pm_results <- co_cc_list %>% 
  map_dfr(. , function(df){
    mod <- clogit(outcome ~ pm + temp_f + strata(id), data = df)
    est <- broom::tidy(mod) %>% filter(term == "pm") %>% 
      select(estimate, conf.low, conf.high) %>% 
      rename(lower95 = conf.low, upper95 = conf.high) %>% 
      mutate_all(exp)
    }) %>% # end map
  cbind(outcomes, .)

# print results
print(pm_results)
```

## Distributed Lag Associations

I believe Rish might use the dlnm package created by Antonio Gasparrini, and I think Rish would like to include him as a co-author, which would be great! I have some trouble using his package for models like the conditional logistic regression or mixed models, so I use steps Ander Wilson has shown me to estimate distributed lag for linear relationships. I think keeping the term as linear is fine in this case since it seems like most outcomes between PM~2.5~ and cardiopulmonary are linear in other studies that have specifically tried to address this question.

First step is to define a function (called distribut_that_lag) that is really long (sorry!) that will take a model with a distributed lag basis function in it and extract the lagged and cumulative results from it. The lag_mod term is where you reference the model, and strata is the strata you'd like to estimate it for. This is used to get out terms for PM~2.5~ smoke and non-smoke. Right now this function only handles lagged matrices of 0-6 days, and degrees of freedom, and will need to be modified if you want to vary this. I can try and make this in to a general function/package for use by Rish if need be.

```{r distributed_lag_fun}
distribute_that_lag <- function(lag_mod, strata, exposure_basis) {
  # output pm basis estimates
  parms <- broom::tidy(lag_mod) %>% 
    filter(stringr::str_detect(term, strata)) %>% 
    select(estimate) %>% 
    as_vector()
  # output estimate names for cov matrix
  names <- stringr::str_subset(names(lag_mod$coefficients), strata)
  # estimate associations
  est <- exposure_basis %*% parms
  # estimate standard error for each interval
  # time variable
  time <- ((rep(1:length(est))-1))
  # covariance matrix for knots 
  cov_mat <- as.matrix(vcov(lag_mod))[names, names]
  # estimate variance of spline
  var <- exp_b %*% cov_mat %*% t(exp_b)
  # estimate lag ----
  # estimate standard error for each lag day for smoke
  l_se <- sqrt(diag(var))
  # calculate lower and upper bound for smoke
  l_est_l95 <- est + (l_se*qnorm(1-0.975))
  l_est_u95 <- est + (l_se*qnorm(0.975))
  l_type <- "lag"
  # lag dataframe
  l_df <- data.frame(strata, l_type, time, 
                     exp(est), exp(l_est_l95), exp(l_est_u95), 
                     row.names = NULL) 
  # assign column names
  colnames(l_df) <- c("strata", "type", "time", 
                      "odds_ratio", "lower_95", "upper_95")
  # cumulative estimates
  c_est <- sapply(seq_along(est), function(x){
    sum(est[1:x])
  })
  # stderr cumulative effect smk
  c_se <- sapply(seq_along(c_est), function(y){
    sqrt(sum(var[1:y,1:y]))
  })
  # estimate 95% CI
  c_l95 <- c_est+(c_se*qnorm(1-0.975))
  c_u95 <- c_est+(c_se*qnorm(0.975))
  # type
  c_type <- "cumulative"
  # return dataframe
  c_df <- data.frame(strata, c_type, time, exp(c_est), 
                     exp(c_l95), exp(c_u95), row.names = NULL) 
  # assign column names
  colnames(c_df) <- c("strata", "type", "time", 
                      "odds_ratio", "lower_95", "upper_95")
  # bind lagged and cumulative 
  lag_est <- rbind(l_df, c_df) %>% 
    mutate(strata = as.character(strata),
           type = as.character(type))
  # return lagged estimate
   return(lag_est)
 } # end lag estimate function
```

### Example Respiratory Mortality
For a example on how I estimate distributed lag, I'll use respriatory deaths associated with lagged PM~2.5~ as an example.

First I'll extract the respiratory case-crossover data from the list and remove values without all 7 PM lagged days.

```{r resp_data}
# output dataframe from list
data <- co_cc_list[[1]] %>% 
    mutate(date = as.Date(date),
           outcome = as.numeric(as.character(outcome))) %>%
    # remove missing lagged data
    filter(!is.na(pm_lag3))
```

Creating lagged PM~2.5~ matrix and temperature in F matrix. Using the complete data created in the step above, I extract the lagged matrices for PM~2.5~ and temperature. Printing out first 6 observations of PM lagged matrix for the case-crossover dataframe.
```{r exposure_matrix}
# create lagged matrix
pm_mat <- as.matrix(select(data, pm, contains("pm_lag")))
temp_mat <- as.matrix(select(data, contains("temp_f")))
# print head of pm_matrix
head(pm_mat)
```

Next I need to define my exposure basis. Here I'm using a natural spline (ns) that is 0 to 6 to create a 7 column basis. Columns here must match the number of columns in the exposure matrix. I've given it 3 degrees of freedom and included the intercept. This will create a 7x3 matrix.
```{r exp_basis}
# define lagged basis spline
exp_b <- ns(0:(ncol(pm_mat)-1), df = 2, intercept = T)
# printing exposure basis
exp_b
```

I now matrix-multiply this exposure basis by the PM and temperature matrix to estimate the PM basis and Temperature basis.
```{r pm_basis}
# pm basis
pm_basis <- pm_mat %*% exp_b
# temp basis
temp_basis <- temp_mat %*% exp_b
# head pm basis
head(pm_basis)
```

Now that I have a pm and temp basis with 3 knots, I add both those to a clogit model and create the object, lag_mod.

```{r pm_lag_mod}
# run lagged model
lag_mod <- clogit(outcome ~ pm_basis + temp_basis + strata(id), data = data)
```

We can now use that distribut_that_lag function to extract the cumulative and lagged effect as a dataframe.

```{r resp_pm_lag_est}
# estimate lag estimate
lag_est <- distribute_that_lag(lag_mod, strata = "pm", exposure_basis = exp_b) %>% 
    mutate(outcome = "resp") %>% select(outcome, strata:upper_95)

# print lag est
lag_est
```

I think the dataframe is kind of hard to look at sometimes, so I like to plot the results with ggplot. Even though we have daily lagged results, Ander suggests starting with the cumulative effect and seeing if there is anything there. I like this approach as well.

```{r cumulative_resp_plot}
# filter to just cumulative results
cumulative_results <- lag_est %>% filter(type == "cumulative")
# plot results
plot <- ggplot(cumulative_results, aes(x=time, y=odds_ratio)) +
  geom_line(colour = "blue", size = 1) +
  geom_ribbon(aes(ymin = lower_95, ymax = upper_95), 
              fill = "blue", alpha = 0.3) + 
  scale_x_continuous(breaks = c(seq(0,7, by=1))) +
  geom_hline(yintercept = 1, linetype = 2, colour = "red") +
  ylab(expression("Odds Ratio: 10 ug/m^3 increase PM2.5")) +
  xlab("Lagged Days") +
  ggtitle("Cumulative Effect of PM 2.5 on Respiratory Mortality") +
  theme(panel.grid.major.x = element_blank(),
        panel.grid.major.y = element_line(linetype = "dotted"),
        panel.grid.minor = element_blank()) +
  theme_minimal()

print(plot)
```

So in the spring through summer months in Colorado, I'd say there is an association between an increase in county-level PM~2.5~ and the risk for respiratory mortality, where on average, a 10 ug/m^3 increase in county-level PM~2.5~ increases the risk for death by 5%. This association is most-pronounced over a 0 to 2 days of elevated exposure and begins to decline. Note that even though the 95%CI lower bound overlaps 1.0 by a bit, I think there might be something there if this were applied across the entire Western US, or if we used ZIPCODE or the Grid as exposure assigment. 

Before I move on to showing how to calculating interaction models, I'll run this same process over for each outcomes dataframe in the case-crossover list. Here I used lappy instead of map functions to itterate over the list as I can easily modify lapply to parLapply if I want to perform parallel calculations on a computing cluster. The purrr package still doesn't have parallel functionality. However, clogit seems to perform fine with these dataframe sizes I'm workign with in Colorado. This may be different if you use mortality data from the entire Western US.

```{r pm_mortality results}
# distributed lag function
mort_dl_pm_results  <- lapply(co_cc_list, function(x){
  # output dataframe from list
  data <- x %>% 
    mutate(date = as.Date(date),
           outcome = as.numeric(as.character(outcome))) %>%
    # remove missing lagged data
    filter(!is.na(pm_lag3))
  # output outcome name
  out_name <- as.character(unique(data$out_name))
  # print(out_name) # track which outcome dataframe it's on
  # create lagged matrix
  pm_mat <- as.matrix(select(data, pm, contains("pm_lag")))
  temp_mat <- as.matrix(select(data, contains("temp_f")))
  # define lagged basis spline
  exp_b <- ns(0:(ncol(pm_mat)-1), df = 2, intercept = T)
  # pm basis
  pm_basis <- pm_mat %*% exp_b
  # temp basis
  temp_basis <- temp_mat %*% exp_b
  # run lagged model
  lag_mod <- clogit(outcome ~ pm_basis + temp_basis + strata(id), data = data)
  
  # estimate lag estimate
  lag_est <- distribute_that_lag(lag_mod, strata = "pm", 
                                 exposure_basis = exp_b) %>% 
    mutate(outcome = out_name) %>% select(outcome, strata:upper_95)
  return(lag_est)
  }) %>%  #end lappply
  # bind rows
  map_dfr(.,rbind)
```

Plotting cumulative effect of PM~2.5~ on cardiopulmonary mortality for Colorado in the months of April through October from 2010 to 2015. I facet-wrapped by outcome to get the cumulative effect for each outcome, but didn't retain the order. Anyways, there may be an effect of repeated elevated PM~2.5~ on cardiovascular mortality over 3 to 4 days of increased exposure, cardiac arrest over 3 or 4 days. Same with cerebrovascular (stroke most likely). Respiratory mortality appears to be most important on the same day of exposure.

```{r cardpulm_cumulative}
# subsetting to cumulative resutls
cumulative_results <- mort_dl_pm_results %>% filter(type == "cumulative")
# plot results
plot <- ggplot(cumulative_results, aes(x=time, y=odds_ratio)) +
  geom_line(colour = "blue", size = 1) +
  geom_ribbon(aes(ymin = lower_95, ymax = upper_95), 
              fill = "blue", alpha = 0.3) + 
  scale_x_continuous(breaks = c(seq(0,7, by=1))) +
  geom_hline(yintercept = 1, linetype = 2, colour = "red") +
  # adding facet wrap to estimate for each outcome
  facet_wrap(~outcome, scales = "free_y") +
  ylab(expression("Odds Ratio: 10 ug/m^3 increase PM2.5")) +
  xlab("Lagged Days") +
  ggtitle("Cumulative Effect of PM 2.5 on Cardiorespiratory Mortality") +
  theme(panel.grid.major.x = element_blank(),
        panel.grid.major.y = element_line(linetype = "dotted"),
        panel.grid.minor = element_blank()) +
  theme_minimal()

print(plot)
```

## Distributed Lag Interaction Model

The interaction model follows similar steps as above, with the difference being that instead of including the interaction model in the model, we create matrices of the interacted PM~2.5~ when the smoke indicator is 0 and when it is 1. I'll use my respiratory outcomes dataset again as an example. I'll also create a new matrix using the lagged smoke > 5 (estimate - diff > 5 and hms > .50) binary indicator of smoke. 

```{r dl_interaction_matrices}
# output dataframe from list
data <- co_cc_list[[1]] %>% 
    mutate(date = as.Date(date),
           outcome = as.numeric(as.character(outcome))) %>%
    # remove missing lagged data
    filter(!is.na(pm_lag3))

# create lagged matrix
pm_mat <- as.matrix(select(data, pm, contains("pm_lag")))
temp_mat <- as.matrix(select(data, contains("temp_f")))
smk_mat <- as.matrix(select(data, contains("smoke5_hms")))
# define lagged basis spline using same exposure basis used above
exp_b <- ns(0:(ncol(pm_mat)-1), df = 3, intercept = T)  
# create temp basis
temp_basis <- temp_mat %*% exp_b
```

To create the PM in the presence of smoke basis, I multiply each element/cell of PM~2.5~ matrix by the same cell in the lagged smoke matrix of 0 and 1 values. If there is smoke that day, the value will by 1xPM~2.5~, if not, the value will be set to 0. 

```{r pm_smk_nosmk_mat}
# pm on smoke days matrix
pm_smk_mat <- pm_mat * smk_mat
# pm smoke basis
pm_smk_basis <- pm_smk_mat %*% exp_b
# pm on  non-smoke days matrix
pm_nosmk_mat <- pm_mat * ifelse(smk_mat == 1, 0, 1)
# pm no smoke basis
pm_nosmk_basis <- pm_nosmk_mat %*% exp_b
# create smoke basis; this needs a longer name since I use string search commands
# to find terms in the model
smoke_basis <- smk_mat %*% exp_b
```

I then add the basis PM~2.5~ when smoke is present, the basis PM~2.5~ when smoke is not present, and the binary smoke basis to the clogit model. I've included the temperature basis as well.

```{r interaction_lagged_model}
# run lagged model
lag_mod <- clogit(outcome ~ pm_smk_basis + pm_nosmk_basis + smoke_basis + 
                    temp_basis + strata(id), data = data)
```

Using distribute_that_lag function to get estimates for the PM~2.5~ smoke strata, PM~2.5~ no smoke strata, and smoke binary strata.

```{r extract_pm_strata_estimates}
# define a vector of strata terms
strata_terms <- c("pm_smk_basis", "pm_nosmk_basis", "smoke_basis")
# estimate cumulative and lagged effect for each basis
lagged_estimates <- strata_terms %>% 
  map_dfr(~distribute_that_lag(lag_mod = lag_mod, strata = ., 
                               exposure_basis = exp_b)) %>% 
  mutate(outcome = "resp", smoke = "smoke5_hms") %>% 
  select(outcome, smoke, strata:upper_95)
# view first 6 rows
head(lagged_estimates)
```

The function/process above created a tidy dataframe that contains lagged and cumulative estimates for each strata (pm with smoke, pm no smoke, and smoke). I'll plot the distributed lag effect for each term.

```{r dl_int_plot}
# limit to cumulative results
cumulative_results <- lagged_estimates %>% 
  filter(type == "cumulative")
# plot results
plot <- ggplot(cumulative_results, aes(x=time, y=odds_ratio)) +
  geom_line(colour = "blue", size = 1) +
  geom_ribbon(aes(ymin = lower_95, ymax = upper_95), 
              fill = "blue", alpha = 0.3) + 
  scale_x_continuous(breaks = c(seq(0,7, by=1))) +
  geom_hline(yintercept = 1, linetype = 2, colour = "red") +
  # adding facet wrap to estimate for each outcome
  facet_wrap(~strata, scales = "free_y") +
  ylab(expression("Odds Ratio")) +
  xlab("Lagged Days") +
  ggtitle("Cumulative Effect of PM 2.5 on Respiratory Mortality") +
  theme(panel.grid.major.x = element_blank(),
        panel.grid.major.y = element_line(linetype = "dotted"),
        panel.grid.minor = element_blank()) +
  theme_minimal()
# print plot
print(plot)
```

The two PM plots are the odds ratio for a 10 ug/m^3^ increase for PM~2.5~ without smoke, and PM~2.5~ with smoke. For the left-most plot, it looks like there is around a 9% increase risk of respiratory mortality on the same day for a 10 ug/m^3 increase in PM~2.5~, which may persit for a day or two. As for PM~2.5~ on a smoke day, it appears there is an inverse association on the same day, perhaps expalined by behavior modifications or other preventative measures? The binary smoke exposure shows an elevated risk of aroudn 150% though due to the effect of smoke alone. I'm not quite sure what to make of this, or even if this strata should be included for interpretation. In a standard interaction model, I may interpret this as the effect of smoke, controlling for the PM~2.5~ pathway. I suppose there could be other pollutants or pathways that are more important for respiratory motality? There is also some possibility of some misclassification of a smoke day since I have required a smoke day to also be at least >5 units as well as smoke over a county of at least 50%.

These analyses can be scaled up to run for multiple outcomes or in parallel if the compuations take a bit. 

## Using the DLNM package

Set up cross-basis for PM2.5 for respiratory mortality.
```{r dlnm}
# create lagged matrix
pm_mat <- as.matrix(select(data, pm, contains("pm_lag")))
temp_mat <- as.matrix(select(data, contains("temp_f")))

# crossbasis of pm
cb_pm <- crossbasis(pm_mat, argvar = list(fun="ns", df = 2), lag = 3, 
                    arglag = list(fun="ns", knots = 2, intercept = T))

# temp cv
cb_temp <- crossbasis(temp_mat, argvar = list(fun="ns", df = 2), lag = 3, 
                    arglag = list(fun="ns", knots = 2, intercept = T))
```

Conditional logistic model.

```{r}

# clogit model
resp_dl_mod <- clogit(outcome ~ cb_pm + temp_f + strata(id), data = data)
BIC(resp_dl_mod)
```

Cross-prediction.

```{r}
# cross-basis prediction 
cb_pred <- crosspred(basis = cb_pm, model = resp_dl_mod, cen = .5, 
                     at = seq(1, 2.5, .5))
```

Cumulative effect at each PM level.
```{r}
cumulative_plot <- tibble(cb_pred$predvar, cb_pred$allRRfit, cb_pred$allRRlow,
                          cb_pred$allRRhigh)
# col names
names(cumulative_plot) <- c("pm_var", "odds_ratio", "lower95", "upper95")

cumulative_plot <- mutate(cumulative_plot, pm_var = pm_var*10)

ggplot(data=cumulative_plot, aes(x=pm_var, y=odds_ratio)) +
    geom_point(color = "blue") + 
    geom_errorbar(aes(ymin=lower95, ymax=upper95), color = "blue", size = 0.3) +
    geom_hline(yintercept = 1, linetype=2) +
    ylab("Odds Ratio") +
    xlab("PM2.5 ug/m^3") +
    ggtitle("Respiratory Cumulative Effect by PM2.5 Level") +
    theme_minimal()
```

Map.

```{r}
# distributed lag function
mort_dlnm_results  <- lapply(co_cc_list, function(x){
  # output dataframe from list
  data <- x %>% 
    mutate(date = as.Date(date),
           outcome = as.numeric(as.character(outcome))) %>%
    # remove missing lagged data
    filter(!is.na(pm_lag3))
  # output outcome name
  out_name <- as.character(unique(data$out_name))
  # print(out_name) # track which outcome dataframe it's on
  # create lagged matrix
  pm_mat <- as.matrix(select(data, pm, contains("pm_lag")))
  temp_mat <- as.matrix(select(data, contains("temp_f")))
  # crossbasis of pm
  cb_pm <- crossbasis(pm_mat, argvar = list(fun="ns", df = 2), lag = 3, 
                    arglag = list(fun="ns", knots = 2, intercept = T))
  # temp cb
  cb_temp <- crossbasis(temp_mat, argvar = list(fun="ns", df = 2), lag = 3, 
                    arglag = list(fun="ns", knots = 2, intercept = T))
  # run lagged model
  lag_mod <- clogit(outcome ~ cb_pm + cb_temp + strata(id), data = data)
  # cross-predict
  # cross-basis prediction 
  cb_pred <- crosspred(basis = cb_pm, model = lag_mod, cen = .5, 
                     at = seq(1, 2, .1))
  # cumulative results
  cumulative_results <- tibble(cb_pred$predvar, cb_pred$allRRfit, 
                               cb_pred$allRRlow, cb_pred$allRRhigh)
  # col names
  names(cumulative_results) <- c("pm_var", "odds_ratio", "lower95", "upper95")
  # final estimate
  cumulative_results <- cumulative_results %>% 
    mutate(outcome = out_name,
           pm_level = pm_var*10) %>% 
    select(outcome, pm_level, odds_ratio:upper95)
  return(cumulative_results)
  }) %>%  #end lappply
  # bind rows
  map_dfr(.,rbind)

head(mort_dlnm_results)
```

Plot

```{r}
ggplot(data=mort_dlnm_results, aes(x=pm_level, y=odds_ratio)) +
    geom_line(color = "blue") + 
    geom_ribbon(aes(ymin=lower95, ymax=upper95), fill = "blue", alpha = 0.3) +
    geom_hline(yintercept = 1, linetype=2) +
    facet_wrap(~outcome, scales = "free_y") +
    ylab("Odds Ratio") +
    xlab("PM2.5 ug/m^3") +
    ggtitle("Respiratory Cumulative Effect by PM2.5 Level") +
    theme_minimal()
```


## Next Steps

- It looks like the GRID id is not correct for the mortality data. This could be because it was assigned wrong when geocoding was taking place? Anyways, I'm going to stick with county for now.